\documentclass[main.tex]{subfiles}
\begin{document}


\chapter{Differentialrechnung und Integralrechnung (Riemann)}


\section{Fundamentalsätze}

\begin{Theorem}[Fundamentalsatz der Differential- und Integralrechnung]
  Sei $I \subseteq \R$ ein Intervall, $a \in I$, $f: I \to \R$ stetig. Definiere $F: I \to \R$ durch
  $$F(x) = \int_a^xf(t)dt$$
  (falls $x < a$)\\
  Dann ist $F$ stetig differenzierbar und es gilt:
  $$F'(x) = f(x)$$
  \begin{itemize}
    \item Diese Funktion $F$ nennen wir \textbf{Stammfunktion} von $f$.
    \item Jede stetige Funktion $f: i \to \R$ besitzte eine Stammfunktion (aber nicht notwendigerweise genau eine).
    \item 2 Stammfunktionen von $f$ unterscheiden sich durch eine Konstante.
    \item Für eine beliebige Stammfunktion gilt:
      $$F(x) = \int_a^x f(t)dt + C$$
      \begin{Bemerkung}[allgemeine Darstellung]
        $$\int f(x) dx = F + C$$
        $$\underbrace{F = \int f(x) dx + C}_{F' = f}$$
      \end{Bemerkung}
  \end{itemize}
\end{Theorem}

\begin{Korollar}
  Sei $f: I \to \R$ stetig, $F$ eine Stammfunktion von $f$. Dann gilt:
  $$\int_a^b f(t)dt = F(b) - F(a)$$
\end{Korollar}

\begin{Beweis}
  $$\E C \in \R : F(x) = \int_a^x f(t)dt + C \A x \in I$$
  Jetzt gilt:
  $$F(a) = \underbrace{\int_a^a f(t)dt}_{=0} + C \Rightarrow C = F(a)$$
  $$F(b) = \int_a^b f(t)dt + F(a) \Leftrightarrow \int_a^b f(t)dt = F(b) - F(a)$$
\end{Beweis}

\begin{Bemerkung}
  $$F = \int f(t) dt \Rightarrow \int_a^b f(t)dt = F(b) - F(a) = [F(x)]_a^b = F\mid_a^b$$
\end{Bemerkung}

\begin{Korollar}
  Sei
  $$f(T) \sum \limits_{n=0}^\infty a_n T^n$$
  eine Potenzreihe mit Konvergenzradius $R > 0$. Somit ist
  $$f:(-R,R) \to \R \text{ mit } f(x) = \sum \limits_{n=0}^\infty a_n x^n$$
  eine stetige Funktion. Die Funktion $f$ ist differenzierbar und es gilt:
  $$f'(x) = \sum \limits_{n=0}^\infty n \cdot a_n x^{n-1}$$
  \begin{Bemerkung}
    Also gilt $f \in C^\infty$.
  \end{Bemerkung}
\end{Korollar}

\begin{Beweis}
  Setze
  $$g(T) = \sum \limits_{n=0}^\infty (n+1) a_{n+1} T^n \in \R[\![T \!]\!]$$
  Konvergenzradius von $g$:
  $$\limsup_{n \to \infty} \sqrt[n]{(n+1) |a_{n+1}|} = \limsup_{n \to \infty} 1 \cdot \sqrt[n]{|a_{n+1}|} = \dfrac{1}{R}$$
  Folgt:
  $$g:(-R,R) \to \R \text{ mit } g(x) = \sum \limits_{n=0}^\infty n a_n x^{n-1}$$
  ist stetig. Also gilt:
  $$\int_0^x g(t)dt = \sum \limits_{n=1}^\infty \int_0^x n a_n t^{n-1} dt =  \sum \limits_{n=1}^\infty [a_n t^n]_0^x =  \sum \limits_{n=1}^\infty a_n x^n = f(x) - \underbrace{f(0)}_{a_0}$$
  $$\Rightarrow g = f + C \Leftrightarrow f' = g$$
\end{Beweis}

\begin{Beispiel}
  Wir wollen zeigen:
  $$\sum \limits_{n = 1}^\infty \dfrac{(-1)^n}{n} = -\log(2)$$
  Betrachte hierfür:
  $$f:(-1,1) \to \R \text{ mit } f(x) = \sum \limits_{n=1}^\infty \dfrac{(-1)^n}{n} \cdot x^n$$
  $f$ ist stetig differenzierbar und es gilt
  $$\begin{aligned}
    f'(x) &= \sum \limits_{n=1}^\infty \dfrac{(-1)^n}{n} n x^{n-1}\\
    &= \sum \limits_{n=1}^\infty (-1)^n x^{n-1}\\
    &= \dfrac{-1}{1+x}
  \end{aligned}$$
  Wir wissen: $\log(y)' = \dfrac{1}{y}$ für $y > 0$. Also $(- \log(1+x))' = \dfrac{-1}{1+x}$.\\
  Folgt:
  $$f(x) = - \log(1+x) + C$$
  Aus der Funktionsdefinition folgt: $f(0) = 0$ aber auch $= - \log(1+0) + C = 0 + C \Rightarrow C = 0$
  $$\Rightarrow -\log(1+x) =\sum \limits_{n=1}^\infty \dfrac{(-1)^n}{n} x^n \A x \in (-1,+1)$$
  Die Funktion $x \to - \log(1+x)$ ist stetig auf $(-1,+1]$ und die Reihe $\sum \frac{(-1)^n}{n} 1^n$ konvergiert. Jetzt folgt laut abel'schem Grenzwertsatz:
  $$\sum \limits_{n = 1}^\infty \dfrac{(-1)^n}{n} = - \log(1+1) = - \log(2)$$
\end{Beispiel}


\section{Integrationsmethoden}

\begin{Theorem}[Eigenschaften des Integrals]
  \begin{itemize}
    \item Invertieren der Intergrationsgrenzen
    $$\int_a^b f(x)dx = - \int_b^a f(x)dx$$
    \item Additivität
    $$\int_a^b (f(x)+g(x))dx = \int_a^b f(x)dx + \int_a^b g(x)dx$$
    \item Linearität
    $$\int_a^b r*f(x)dx = r*\int_a^b f(x)dx$$
    \item Abschnittweise Integration
    $$\int_a^b f(x)dx +\int_b^c f(x)dx = \int_a^c f(x)dx$$
  \end{itemize}
\end{Theorem}

\begin{Theorem}[Partielle Integration]
  Es seien $f,g: I \to \R$ stetig differenzierbar, und $F,G$ ihre jeweiligen Stammfunktionen. Dann gilt:
  $$\int f(x)'g(x) dx= f(x)g(x) - \int f(x)g'(x) dx$$
  Oder, ohne die Voraussetzung der Differenzierbarkeit an $f$ und $g$:
  $$\int F g dx = FG - \int f G dx$$
\end{Theorem}

\begin{Beweis}
  Durch Ableiten erhält man wieder:
  $$F g = fG + Fg - fG$$
\end{Beweis}

\begin{Beispiel}
  Berechne:
  $$\int \underbrace{x}_{F} \underbrace{\exp(x)}_{g} dx$$
  Setze: $f(x) = 1$, $G(x) = \exp(x)$. Dann gilt:
  $$\begin{aligned}
    \int x \exp(x) dx &= F(x)G(x) - \int 1 \exp(x)dx \\
    &= x \exp(x) x - \exp(x) + C\\
    &= (x-1) \exp(x)
  \end{aligned}$$
\end{Beispiel}

\begin{Beispiel}
  Berechne:
  $$\int \log(x)dx$$
  Setze: $f(x) = (\log(x))' = \dfrac{1}{x}$, $G(x) = x$
  Also ist
  $$= \log(x)x - \int \dfrac{1}{x}x dx = x (\log(x)-1) + C$$
  Kann auch durch ableiten nachgeprüft werden.
\end{Beispiel}

\begin{Theorem}[Substitution]
  Seien $I,J \subseteq \R$ Intervalle und seien $f: I \to J$, $G: J \to \R$ Funktionen mit $g = G'$ und $f,G$ stetig differenzierbar.\\
  $$G(f(x))' = g(f(x))\cdot f'(x) \text{ (Kettenregel)}$$
  Folgt:
  $$\int g(f(x)) \cdot f'(x)dx = \int G(f(x))'dx = G(f(x)) + C$$
  Mit $u = f(x)$ kann man schreiben
  $$\int g(f(x)) \cdot f'(x)dx = \int g(u) du$$
  Für bestimmte Integrale muss man die Anpassung der Intergrationsgrenzen beachten:
  $$\int_a^b g(f(x)) \cdot f'(x)dx = \int_{f(a)}^{f(b)} g(u) du$$
\end{Theorem}

\begin{Beispiel}
  \begin{itemize}
    \item $\int \dfrac{x}{1+x^2}dx = \dfrac{1}{2}\int \dfrac{1}{1+x^2}(2x)dx$. Also gilt:
      \begin{itemize}
        \item $u = 1+x^2$
        \item $u' = 2x$
        \item $g(u) = \dfrac{1}{u}$
      \end{itemize}
      $$\Rightarrow \dfrac{1}{2}\int \dfrac{1}{1+x^2}(2x)dx = \dfrac{1}{2} \int \dfrac{1}{u} du = \dfrac{1}{2}\log(u) = \dfrac{1}{2}\log(1+x^2)$$
      $$\int_a^b \dfrac{x}{1+x^2}dx = \left[\dfrac{1}{2} \log(u)\right]_{a^2+1}^{b^2+1} = \left[\dfrac{1}{2} \log(1+x^2)\right]_a^b$$
    \item $\int \sqrt{r^2 - x^2} dx$. Substitution:
      \begin{itemize}
        \item $x = r \sin(\vartheta) = f(\vartheta)$
        \item $d x = df(\vartheta) = r \cos(\vartheta)d \vartheta$
        \item $g(x)$ bleibt weiterhin: $g(x) = \sqrt{r^2 - x^2}$
      \end{itemize}
      \begin{align*}
        \int\sqrt{r^2 - x^2}dx &= \int \underbrace{\sqrt{r^2 - {\underbrace{r^2 sin(\vartheta)}_{f(\vartheta)}}^2}}_{g(f(\vartheta))} \cdot \underbrace{r \cos(\vartheta)}_{f'(\vartheta)}d \vartheta\\
        &= r^2 \int \cos(\vartheta)^2 d \vartheta\\
        &= r^2 \int \dfrac{1 + \cos(2\vartheta)}{2} d \vartheta
      \end{align*}
      Durch erneute Substitution $\varphi = 2 \vartheta$, $d \vartheta = 2 d \vartheta$ erhält man:
      \begin{align*}
        r^2 \int \dfrac{1 + \cos(2\vartheta)}{2} d \vartheta &= \dfrac{r^2}{2} \int \dfrac{1}{2} + \dfrac{1}{2}\cos(\varphi)d \varphi\\
        &= \dfrac{r^2}{4} \left( \int 1 d \varphi + \int\cos(\varphi)d \varphi \right)\\
        &= \dfrac{r^2}{4} (\varphi + \sin(\varphi))\\
        &= \dfrac{r^2}{4} (2 \vartheta + \sin(2 \vartheta))
      \end{align*}
      Jetzt gilt $\vartheta = \arcsin(1/r)$ also folgt:
      \begin{align*}
        \int\sqrt{r^2 - x^2} dx &= \dfrac{r^2}{4} (2 \vartheta + \sin(2 \vartheta))\\
        &= \dfrac{r^2}{4}(2 \arcsin(x/r) + \sin(2 \arcsin(x/r)))\\
        &= \dfrac{r^2}{4}(2 \arcsin(x/r) + \dfrac{1}{2} x \cdot\sqrt{r^2-x^2})+C
      \end{align*}
  \end{itemize}
\end{Beispiel}

\begin{Theorem}
  Integrale der Form $\int \dfrac{P(x)}{Q(x)} dx$ mit $P,Q$ Polynomen konkret berechnen. Im Allgemeinen kann eine beliebige Funktion und insbesondere ihr Integral nicht mit den uns bekannten Funktionen \textbf{nicht} nicht berechnet werden.
\end{Theorem}

\begin{Beispiel}
  $$S(x) = \int_0^x \sin(t^2)dt$$
  Ist stetig und somit auf jeden Fall integrierbar, kann aber nicht konkret berechnet werden.\\
  Probieren wir trotzdem:
  $$S(1) = \int_0^1 \sin(t^2)dt$$
  \begin{itemize}
    \item $\sin(x) = x - \dfrac{x^3}{6} + \dfrac{x^5}{120} - \dfrac{x^7}{7!} + ...$
    \item $\sin(x^2) = x^2 - \dfrac{x^6}{6} + \dfrac{x^10}{120} - \dfrac{x^14}{7!} + ...$
  \end{itemize}
  Also:
  \begin{align*}
    s(1) &= \int_0^1 \left( x^2 - \dfrac{x^6}{6} + \dfrac{x^10}{120} - \dfrac{x^14}{7!} + ...\right)dx\\
    &=\left[ \dfrac{1}{3}x^3 - \dfrac{1}{42}t^7 + \dfrac{1}{1320}t^11 - \dfrac{1}{7! \cdot 15}t^15 + ... \right]_0^1\\
    &= \dfrac{1}{3} - \dfrac{1}{42} + \dfrac{1}{1320} - \dfrac{1}{75600} + ...\\
  \end{align*}
  jetzt kann man mit beliebiger Präzision abschätzen:
  $$\dfrac{1}{3} - \dfrac{1}{42} + \dfrac{1}{1320} > S(1) > \dfrac{1}{3} - \dfrac{1}{42} + \dfrac{1}{1320} - \dfrac{1}{75600}$$
\end{Beispiel}


\subsection{Trigonometrische Identäten}

\begin{Theorem}[Wichtige Winkel]
    $$\begin{array}{|c|c|c|c|c|c|c|c|}
      \hline
      \textbf{Grad}
        & 0^{\circ} & 30^{\circ} & 45^{\circ} & 60^{\circ} & 90^{\circ} \\
      \hline
      \textbf{Radian}
        & 0 & \frac{\pi}{6} & \frac{\pi}{4} & \frac{\pi}{3} & \frac{\pi}{2} \\
      \hline
      \sin \theta
        & 0 & \frac{1}{2} & \frac{\sqrt 2}{2} & \frac{\sqrt 3}{2} & 1\\
      \hline
      \cos \theta
        & 1 & \frac{\sqrt 3}{2} & \frac{\sqrt 2}{2} & \frac{1}{2} & 0\\
      \hline
      \tan \theta
        & 0 & \frac{\sqrt 3}{3} & 1& \sqrt 3 & \\
      \hline
    \end{array}$$
\end{Theorem}

\begin{Theorem}[Additionstheoreme]
  $$\begin{aligned}
    \sin(x + y) &= \sin (x) \cos (y) + \cos (x) \sin (y)\\
    \sin(x - y) &= \sin (x) \cos (y) - \cos (x) \sin (y)\\
    \cos(x + y) &= \cos (x) \cos (y) - \sin (x) \sin (y)\\
    \cos(x - y) &= \cos (x) \cos (y) + \sin (x) \sin (y)\\
    \tan(x + y) &= \dfrac{\tan x + \tan y}{1 - \tan x \tan y}\\
    \tan(x - y) &= \dfrac{\tan x - \tan y}{1 + \tan x \tan y}
  \end{aligned}$$
\end{Theorem}

\begin{Theorem}[Pythagoräische Identäten]
  $$\begin{aligned}
    \sin^2 x + \cos^2 x &= 1\\
    1 + \tan^2 x &= \sec^2 x\\
    1 + \cot^2 x &= \csc^2 x
  \end{aligned}$$
\end{Theorem}

\begin{Theorem}[Halbwinkelidentität]
  $$\begin{aligned}
    \sin \left(\frac{x}{2}\right)  &= \pm \sqrt{ \frac{1 - \cos x }{2} }\\
    \cos \left(\frac{x}{2}\right)  &= \pm \sqrt{ \frac{1 + \cos x }{2} }\\
    \tan \left(\frac{x}{2}\right)  &= \frac{1 - \cos x }{\sin x}\\
                      &= \frac{ \sin x }{ 1 + \cos x }
  \end{aligned}$$
\end{Theorem}
\begin{Theorem}[Doppelwinkelidentität]
  $$\begin{aligned}
    \sin(2x)  &= 2 \sin x \cos x\\
    \cos(2x)  &= \cos^2 x - \sin^2 x\\
              &= 2 \cos^2 x - 1\\
              &= 1 - 2 \sin^2 x\\
    \tan(2x)  &= \frac{2 \tan x}{1 - \tan^2 x}
  \end{aligned}$$
\end{Theorem}

\begin{Theorem}[Summe-zu-Produkt Identät]
  $$\begin{aligned}
    \sin (x) + \sin (y) &= 2 \sin \Big( \frac{x + y}{2} \Big) \cos \Big( \frac{x - y}{2} \Big)\\
    \sin (x) - \sin (y) &= 2 \cos \Big( \frac{x + y}{2} \Big) \sin \Big( \frac{x - y}{2} \Big)\\
    \cos (x) + \cos (y) &= 2 \cos \Big( \frac{x + y}{2} \Big) \cos \Big( \frac{x - y}{2} \Big)\\
    \cos (x) - \cos (y) &= -2 \sin \Big( \frac{x + y}{2} \Big) \sin \Big( \frac{x - y}{2} \Big)\\
    \tan (x) + \tan (y) &= \dfrac{ \sin(x + y) }{ \cos x \cos y}\\
    \tan (x) - \tan (y) &= \dfrac{ \sin(x - y) }{ \cos x \cos y}\\
  \end{aligned}$$
\end{Theorem}

\begin{Theorem}[Produkt-zu-Summe Identät]
  $$\begin{aligned}
    \sin (x) \sin (y) &= \dfrac{1}{2}\big[\cos(x - y) - \cos(x + y)\big]\\
    \cos (x) \cos (y) &= \dfrac{1}{2}\big[\cos(x - y) + \cos(x + y)\big]\\
    \sin (x) \cos (y) &= \dfrac{1}{2}\big[\sin(x + y) + \sin(x - y)\big]\\
    \tan (x) \tan (y) &= \dfrac{ \tan x + \tan y }{ \cot x + \cot y }\\
    \tan (x) \cot (y) &= \dfrac{ \tan x + \cot y }{ \cot x + \tan y }
  \end{aligned}$$
\end{Theorem}

\begin{Theorem}[Reziprokenidentität]
  $$\cot (x) = \dfrac{1}{\tan (x)} \quad \csc (x) = \dfrac{1}{\sin (x)} \quad \sec (x) = \dfrac{1}{\cos (x)}$$
\end{Theorem}

\begin{Theorem}[Kofunktionsidentität]
  $$\begin{aligned}
    \sin \left(\frac{\pi}{2} - x\right) &= \cos x\\
    \cos \left(\frac{\pi}{2} - x\right) &= \sin x\\
    \tan \left(\frac{\pi}{2} - x\right) &= \cot x\\
    \cot \left(\frac{\pi}{2} - x\right) &= \tan x\\
    \sec \left(\frac{\pi}{2} - x\right) &= \csc x\\
    \csc \left(\frac{\pi}{2} - x\right) &= \sec x
  \end{aligned}$$
\end{Theorem}

\begin{Theorem}[Potenzverringerungsidentität]
  $$\begin{aligned}
    \sin^2 x  &= \frac{1 - \cos 2x}{2}\\
    \cos^2 x  &= \frac{1 + \cos 2x}{2}\\
    \tan^2 x  &= \frac{1 - \cos 2x}{1 + \cos 2x}
  \end{aligned}$$
\end{Theorem}


\section{Uneigentliche Integrale}

Nachfolgend werden wir versuchen zu berechnen:
$$\int_{-\infty}^\infty e^{{-x}^2} dx \qquad \int_0^1 \log(x)dx$$

\begin{Definition}
  Seio $I \subseteq \R$ ein Intervall mit Endpunkten $a < b \in \R \cup \{-\infty,\infty\}$. Sei $f: (a,b) \to \R$ stetig (also lokal integrierbar). Wir sagen $\int_a^b f(x)dx$ konvergiert, falls für ein beliebiges $c \in I$ die Grenzwerte
  $$A = \lim \limits_{\substack{x \to a \\ x > a}} \int_x^c f(t)dt \qquad B = \lim \limits_{\substack{x \to b \\ x < b}} \int_c^x f(t)dt$$
  existieren.
  In diesem Fall schreibt man
  $$\int_a^b f(x)dx = A + B$$
\end{Definition}

\begin{Beispiel}
  Sei $f(x) = \log(x)e^{-x}$.\\
  \begin{center}
    \begin{tikzpicture}
      \begin{axis}[
        domain=-1:7,
        axis x line = center,
        %xmajorticks=false,
        %ytick = none,
        axis y line = center,
        xlabel={$x$},
        ylabel={$y$},
        ]
        \addplot[domain=0.1:67,smooth,color=blue,thick] {ln(x) / exp(x)};
      \end{axis}
    \end{tikzpicture}
  \end{center}

  Wir wollen berechnen:
  $$\int_0^\infty \dfrac{\log(x)}{e^x}dx$$
  Zunächst berechnen wir:
  $$\begin{aligned}
    \int_0^1 \log(x)&= \lim \limits_{\substack{t \to 0 \\ t > 0}} \int_t^1 \log(x)dx\\
    &= \lim \limits_{\substack{t \to 0 \\ t > 0}} [ x \log(x) -x]_0^1\\
    &= -1 - \lim \limits_{\substack{t \to 0 \\ t > 0}} (t \log(t) -t)\\
    &= -1
  \end{aligned}$$
\end{Beispiel}

\begin{Theorem}
  Sei $f:[0,\infty] \to \R$ monoton fallend, $f \geq 0$. Dann gilt:
  $$\sum \limits_{n=1}^\infty f(n) \leq \int_0^\infty f(x)dx \leq \sum \limits_{n=0}^\infty f(n)$$
  Insbesondere gilt:
  $$\sum \limits_{n=0}^\infty f(n) \text{ konvergiert} \Leftrightarrow \int_0^\infty f(x)dx \text{ konvergiert}$$
\end{Theorem}

\begin{Beweis}
  $f$ ist der Form:
  \begin{center}
    \begin{tikzpicture}
      \begin{axis}[
        domain=-0.1:7,
        ymin=-0.05, ymax = 0.5,
        axis x line = center,
        ticks = none,
        % ytick = none,
        axis y line = center,
        xlabel={$x$},
        ylabel={$y$},
        legend pos=north east,
        ]
        \addplot[smooth,color=blue,thick] {0.3 / exp(x*x/5)};
        \addlegendentry{$f$}

      \end{axis}
      % \draw (0,0.3) node[left] {$f(0)$};
    \end{tikzpicture}
  \end{center}

  und nach oben beschränkt durch den Wert $f(0)$.

  Sei $N \in \N$, definiere $u:[0,N] \to \R$ durch $u(x) = f(\lceil x\rceil)$. Dann gilt: $u \leq f$ (weil $f$ monoton fallend). Jetzt folgt:
  $$\sum \limits_{n = 1}^N f(n) = \int_0^N u(x)dx \leq \int_0^N f(x)dx$$
  Mit Grenzwert $N \to \infty$ folgt $\sum \limits_{n=1}^\infty f(n) \leq \int_0^\infty f(x)dx$.

  Für die zweite Ungleichung betrachte $o(x) = f(\lfloor x \rfloor)$
\end{Beweis}

\begin{Beispiel}
  $$\sum \limits_{n=1}^\infty \dfrac{1}{n} \quad f(x) = \dfrac{1}{x+1}$$
  $$\int_0^\infty f(x) = \lim \limits_{b \to \infty} [\log(x+1)]_0^b = \lim \limits_{b \to \infty} (\log(b)) - 1 = \infty$$
  Nach dem Satz gilt aber:
  $$\int_0^\infty f(x)dx \leq \sum \limits_{n=0}^\infty f(n) = \sum \limits_{n=1}^\infty \dfrac{1}{n}$$
\end{Beispiel}

\begin{Beispiel}[zu uneigentlichen Integralen generell]
  Sei $\Gamma : (0 , \infty): \to \R$ die Funktion gegeben durch
  $$\Gamma(s) = \int_0^\infty x^{s-1} \cdot \exp(-x)dx$$
  Zunächst müssen wir zeigen, dass dieses Integral für alle postiven $s$ konvergiert.
  $$\int_a^b \underbrace{x^{s-1}}_{f}\underbrace{\exp(-x)}_{G} dx = \left[\dfrac{1}{s}x^s \exp(-x)\right]_a^b + \dfrac{1}{s} \int_a^b \underbrace{x^s \exp(-x)}_{stetig} \quad s > 0, 0 < a < b < \infty$$
  Also existiert $a \to 0$ als Grenzwert:
  $$\int_0^b x^{s-1}\exp(-x) dx = \dfrac{1}{s}b^s \exp(-b) + \dfrac{1}{s} \int_0^b x^s \exp(-x)dx$$
  Es gibt $R > 0$ mit $\exp(x) \geq x^{-s+2} \A x \geq \R$ also $\exp(-x)  \leq x^{-s+2}$, folgt:
  $$\lim \limits_{b \to \infty} \int_a ^b x^s \exp(-x)dx \leq \int_a^R x^s \exp(-x)dx + \lim \limits_{b \to \infty}\int_R^b x^{-2}dx$$
  Jetzt möchten wir ein par Werte berchnen:
  $$\begin{aligned}
    \Gamma(s) &= \int_0^\infty x^{s-1}\exp(-s) dx\\
    &= 0 + \dfrac{1}{s} \int_0^\infty x^s \exp(-x)dx\\
    &= \dfrac{1}{s} \Gamma(s+1)
  \end{aligned}$$
  Also allgemein:
  \begin{Theorem}
    $$\Gamma(s+1) = s \Gamma(s+1)$$
  \end{Theorem}
  Jetzt gilt:
  \begin{itemize}
    \item $\Gamma(1) = 1$
    \item $\Gamma(2) = 1 \Gamma(1) = 1$
    \item $\Gamma(3) = 2 \Gamma(2) = 2$
    \item $\Gamma(4) = 3 \Gamma(3) = 6$
    \item ...
    \item $\Gamma(n) = (n-1)!$
  \end{itemize}
\end{Beispiel}


\section{Taylorreihen}

\subsection{Vorüberlegung}

$$\log(x+1) = \int \dfrac{1}{x+1}dx = \int \sum \limits_{n=0}^\infty (-1)^n x^n dx = \sum \limits_{n=0}^\infty \int \dfrac{(-1)^n x^n}{n+1}$$
für $x \in (-1,1)$.

Sei $f:(-R,R) \to \R$ eine Funktion gegeben durch eine Reihe
$$f(x) = \sum \limits_{n=0}^\infty a_n x^n$$
mit Konvergenzradius $> R$. Dann gilt: $a_0 = f(0)$. Außerdem
$$f'(x) = \sum \limits_{n=0}^\infty n a_n x^{n-1} = \sum \limits_{n=0}^\infty (n+1) a_{n+1} x^n$$
Also gilt: $f'(0) = (0+1) a_1 = a_1$

Weiterhin:
$$f''(0) = \sum \limits_{n=0}^\infty n(n-1) a_{n} x^{n-2}$$
Also gilt: $f''(0) = 2(2-1) a_2 = 2 a_2$ und allgemein gilt: $a_n = \dfrac{1}{n!} f^{(n)}(0)$.

Als Konsequenz halten wir fest:

\begin{Theorem}
  $$\sum \limits_{n=0}^\infty a_n x^n = \sum \limits_{n=0}^\infty b_n x^n \text{ für $x$ klein genug} \Leftrightarrow a_n = b_n \A n$$
\end{Theorem}

\begin{Definition}[Taylor-Notation]
  Sei $D \subseteq \R$ ein Intervall, $x_0 \in D$ fix. Sei $f: D \to \R$ von Klasse $C^n$. Setze
  $$P_n(x) = \sum \limits_{k=0}^n \dfrac{f^{(k)} (x_0)}{k!} \cdot (x - x_0)^k$$
  Und für $f \in C^\infty$:
  $$L(T) = \sum \limits_{k=0}^\infty \dfrac{f^{(k)} (x_0)}{k!} T^k \in \R[\![T]\!]$$
  Nenne $P_n$ die $n$-te \textbf{Taylor-Approximation} an $f$ bei $x_0$, und $L(T)$ die \textbf{Taylor-Reihe} von $f$ bei $x_0$.
\end{Definition}

\begin{Bemerkung}
  Die Tailor-Reihen stellen somit die optimale polynomiale Annäherung einer beliebigen Funktion dar.
\end{Bemerkung}

\begin{Bemerkung}
  Man hätte $P_n$ alternativ auch definieren können als:
  $$P_n(x) = \text{ Die eindeutig bestimmte Polynomfunktion vom Grad $n$ mit}$$
  $$P_n^{(k)} (x_0) = f^{(k)}(x_9) \A k \leq n$$
\end{Bemerkung}

\subsection{Taylor-Approximation}

\begin{Theorem}[Taylor-Approximation]
  Sei $D \subseteq \R$ ein Intervall, $x_0 \in D$ fix. Sei $f: D \to \R$ von Klasse $C^{n+1}$. Dann gilt, für \textbf{alle} $x \in D$
  $$f(x) = P_n(x) + \int_{x_0}^x f^{(n+1)}(t) \dfrac{(x-t)^n}{n!}dt$$
  Der zweite Term $R_n = f - P_n$, das Restglied, ist ein Fehlerterm und ist die Kernaussage des Satzes.
\end{Theorem}

\begin{Beweis}
  Induktion und partielle Integration:
  \begin{itemize}
    \item $n = 0$:
      $$\begin{aligned}
        f(x) &= P_0(x) + \int_0^x f^{(1)} t \dfrac{1}{0!}dt\\
        &= f(x_0) + \int_0^x f'(t)dt
      \end{aligned}$$
      \checkmark
    \item Angenommen, der Satz gilt für $n - 1$:
      $$\begin{aligned}
        f(x) &= P_{n-1}(x) + \int_{x_0}^x f^{(n)} (t) \dfrac{(x-t)^{n-1}}{(n-1)!}dt \\
        &= \underbrace{P_{n-1}(x) + \left[f^{(n)} (t) \dfrac{(x-t)^n}{n!}\right]_{x_0}^x}_{P_n(x)} + \underbrace{\int_{x_0}^x f^{(n+1)} \dfrac{(x-t)^n}{n!}dt}_{R_n(x)}
      \end{aligned}$$
  \end{itemize}
\end{Beweis}

\begin{Korollar}[Taylor-Abschätzung]
  Sei $I \subseteq \R$ ein Intervall, $x_0 \in I$, $f: I \to \R$ von Klasse $C^{n+1}$. Sei $\delta > 0$ und setze
  $$M = \sup\{|f^{(n+1)}(t)| \mid t \in [x_0-\delta, x_0 + \delta]\}$$
  Dann gilt für $x \in [x_0-\delta, x_0 + \delta]$:
  $$|f(x) - P_n(x)| \leq \dfrac{M \cdot |x - x_0|^{n+1}}{(n+1)!} = \underbrace{\mathcal{O}((x-x_0)^{n+1})}_{\text{für }x \to x_0}$$
\end{Korollar}

\begin{Beweis}
  Angenommen $x_0 \leq x$:
  $$\begin{aligned}
    |f(x) - P_n(x)| = |R_n(x)| &= \left|\int_{x_0}^x f^{(n+1)} \dfrac{(x-t)^n}{n!} dt \right|\\
    &\leq  \int_{x_0}^x \left| f^{(n+1)} \dfrac{(x-t)^n}{n!} \right| dt\\
    &\leq M \int_{x_0}^x \dfrac{(x-t)^n}{n!} dt = M \dfrac{(x - x_0)^{n+1}}{(n+1)!}
  \end{aligned}$$
  Für den Fall $x_0 > x$, gilt:
  $$\begin{aligned}
    \left|\int_{x_0}^x f^{(n+1)} \dfrac{(x-t)^n}{n!} dt \right| &\leq \int_{x}^{x_0} \left| f^{(n+1)} \dfrac{(x-t)^n}{n!} \right| dt\\
    &= -\int_{x_0}^{x} \left| f^{(n+1)} \dfrac{(x-t)^n}{n!} \right| dt\\
    &\leq -M \int_{x_0}^x \dfrac{(x-t)^n}{n!} = M \dfrac{(x_0 - x)^{n+1}}{(n+1!)}
  \end{aligned}$$
  Folgt:
  $$|f(x) - P_n(x)| = |R_n(x)| \leq  M \dfrac{|x_0 - x|^{n+1}}{(n+1)!}$$
\end{Beweis}

\begin{Definition}[Analytische Funktionen]
  Sei $I \subseteq \R$ ein Intervall, $f:I \to \R$ eine glatte Funktion. Wir sagen, $f$ sei \textbf{analytisch} falls für jedes $x_0\in I$ ein $\delta > 0$ existiert mit
  $$f(x) = \sum \limits_{n=0}^\infty \dfrac{f^{(n)}(x_0)}{n!} (x -x_0)^n$$
  für alle $x \in [x_0 -\delta,x_0 +\delta]$
\end{Definition}

\begin{Bemerkung}
  Das entspricht der Aussage: $f(x) = \limn P_n(x)$, also $\limn R_n(x) = 0$
\end{Bemerkung}

\begin{Bemerkung}
  \begin{Theorem}
    Sei $f : (-R,R) \to \R$ gegeben durch eine Potenzreihe mit Konvergenzradius $R$. Dann ist $f$ analytisch.
  \end{Theorem}
  Also zum Beispiel $\sin, \cos, \exp, ...$ und alle daraus zusammengesetzten Funktionen.
  \begin{Beweis}
    Betrachte $x_0 \in (-R,R)$ und $\delta > 0$, so dass $[x_0 - \delta,x_0+\delta] \subseteq (-R,R)$.
    $$\begin{aligned}
      f(x) &= \sum \limits_{n=0}^\infty a_nx^n\\
      &= \sum \limits_{n=0}^\infty a_n(x-x_0 + x_0)^n\\
      &= \sum \limits_{n=0}^\infty a_n \cdot \sum \limits_{k=0}^n {n \choose k} x_0^{n-k}(x-x_0)^k\\
      &= \sum \limits_{k=0}^\infty\left( \underbrace{\sum \limits_{n=k}^\infty a_n{n \choose k} x_0 ^{n-k}}_{b_k}\right)(x - x_0)^k\\
      & \text{Umordnung möglich weil die Reihen absolut} \\
      & \text{konvergieren, wegen der Wahl von } x_0\\
      &= \sum \limits_{k=0}^\infty b_k (x-x_0)^k
    \end{aligned}$$
  \end{Beweis}
\end{Bemerkung}

\begin{Bemerkung}[Rigidität/Starrheit analytischer Funktionen]
  \begin{Theorem}
      Sei $I \subseteq \R$ ein Intervall, $f,g:I \to \R$ analytisch. Angenommen es existiert ein $x_0 \in I$, $\delta > 0$ mit $f(x) = g(x) \A x \in (x_0 -\delta, x_0 + \delta)$.

      Dann gilt
      $$f(x) = g(x) \A x \in I$$
  \end{Theorem}
  \begin{Beweis}
    Setze $s = \sup\{x \in I \mid x \geq x_0, f(x) = g(x)\}$ also $s \in I$ und $f(s) = g(s)$ (weil $f$ und $g$ stetig sind) und sogar $f(x) = g(x) \A x\in (x_0,s]$.

    Betrachte die Tailor-Reihen für $x \in (s-\varepsilon, s+ \varepsilon)$:
    $$f(x) = \sum \limits_{n=0}^k a_n (x-s)^n \qquad g(x) = \sum \limits_{n=0}^k b_n (x-s)^n$$
    Man berechnet nun:
    $$a_n = \dfrac{f^{(n)}(s)}{n!} \qquad b_n = \dfrac{g^{(n)}(s)}{n!}$$
    Berechne die Ableitungen 'von links': wegen $f(x) = g(x)$ für $x_0 \leq x \leq s : a_n = b_n$.

    Folgt: $f(x) = g(x) \A x \in [x_0,s] \cup (s- \varepsilon,s+\varepsilon)$ also $x \in [x_0,s+\varepsilon)$. Somit entsteht ein Widerspruch zur Definition von $s$.
  \end{Beweis}
\end{Bemerkung}

\begin{Beispiel}
  Wir schreiben $\Psi: \R \to \R$ für die Funktion gegeben durch:
  $$\Psi(x)= \left\{\begin{aligned}
    \exp\left(-\dfrac{1}{x}\right) & \quad x > 0\\
    0 & \quad x \leq 0
  \end{aligned}\right.$$
  \begin{center}
    \begin{tikzpicture}[yscale=0.7]
      \begin{axis}[
        domain=-0.5:10,
        axis x line = center,
        axis y line = center,
        xlabel={$x$},
        ylabel={$y$},
        ]
        \addplot[smooth,color=blue,thick,domain=0.01:10] {exp(-1/x)};
        \addplot[smooth,color=blue,thick,domain=-2:0.01] {0};
      \end{axis}
    \end{tikzpicture}
  \end{center}

  Behauptung $\Psi$ ist \textbf{glatt.}

  Für $x > 0$ gilt: $\Psi'(x) = \dfrac{1}{x^2} \exp\left(-\dfrac{1}{x}\right)$

  Für $x \leq 0$ gilt: $\Psi'(x) = 0$

  Es gilt
  $$\lim \limits_{\substack{x \to 0 \\ x > 0}} \Psi'(x) = \lim \limits_{x \to 0 \\ x > 0} \dfrac{\exp\left(-\dfrac{1}{x}\right)}{x^2} = \lim \limits_{y \to \infty} y^2 \exp(-y) = 0$$
  Für $x > 0$ gilt: $\Psi''(x) = \left(-\dfrac{2}{x^3} + \dfrac{1}{x^4}\right) \exp\left(-\dfrac{1}{x}\right)$

  Es gilt
  $$\lim \limits_{\substack{x \to 0 \\ x > 0}} \Psi''(x) = P(y)\cdot\exp(-y) = 0$$
  Induktiv: $\Psi^{(n)}(x) = P_n\left(\dfrac{1}{x}\right) \cdot \exp\left(-\dfrac{1}{x}\right)$ für $x > 0$.
  $$\Psi^{(n+1)}(x) =
  \left[
   \underbrace{ \left(P_n\left(\dfrac{1}{x}\right)\right)' + P_n\left(\dfrac{1}{x}\right)\cdot \dfrac{1}{x^2}}_{P_{n+1}(1/x)}
  \right] \cdot \exp\left(-\dfrac{1}{x}\right)$$
  Folgt: $\Psi$ ist nicht analytisch.
\end{Beispiel}


\section{Numerische Methoden}

\subsection{Newton-Cotes Verfahren}

Wir wollen
$$\int_a^b f(x)dx$$
numerisch berechnen, für gegebene $a$, $b$ und $f$ (stetig).

Sei $n \in \N_{>0}$. Setze $x_k = a + \dfrac{b-a}{n}k$ also $a = x_0 < x_1 < ... < x_n = b$.
\begin{center}
  \definecolor{lightblu}{rgb}{0,0,0.3}
\definecolor{lightre}{rgb}{0.3,0,0}
\begin{tikzpicture}[scale=0.7]
  \draw (-0.3,0.3) node {$O$};
  \draw[->,line width=0.8pt] (-5.5,0) -- (5.5,0) node[below] {$x$};
  \draw[->,line width=0.8pt] (0,-5) -- (0,5.5) node[right] {$y$};
  \draw[line width=1.5pt,color=red] (-5,2) ..controls(-2,-4) ..(0,0);
  \draw[line width=1.5pt,color=red] (0,0) ..controls(2,4) ..(5,5);
  %\draw[line width=0.8pt,fill=lightblu,fill opacity=0.2] (0.5,0) -- (0.5,2.4) -- (1.25,2.4) -- (1.25,0) -- cycle;
  %\draw[line width=0.8pt,fill=lightblu,fill opacity=0.2] (1.25,0) -- (1.25,3.5) -- (2,3.5) -- (2,0) -- cycle;
  %\draw[line width=0.8pt,fill=lightblu,fill opacity=0.2] (2,0) -- (2,4.1) -- (2.75,4.1) -- (2.75,0) -- cycle;
  %\draw[line width=0.8pt,fill=lightblu,fill opacity=0.2] (2.75,0) -- (2.75,4.5) -- (3.5,4.5) -- (3.5,0) -- cycle;
  \draw[line width=0.8pt,fill=lightblu,fill opacity=0.2] (0.5,0) -- (0.5,1) -- (1.25,1) -- (1.25,0) -- cycle;
  \draw[line width=0.8pt,fill=lightblu,fill opacity=0.2] (1.25,0) -- (1.25,2.4) -- (2,2.4) -- (2,0) -- cycle;
  \draw[line width=0.8pt,fill=lightblu,fill opacity=0.2] (2,0) -- (2,3.5) -- (2.75,3.5) -- (2.75,0) -- cycle;
  \draw[line width=0.8pt,fill=lightblu,fill opacity=0.2] (2.75,0) -- (2.75,4.1) -- (3.5,4.1) -- (3.5,0) -- cycle;
  \draw[line width=1.2pt,color=orange] (0.5,1) -- (0.5,0) node[below] {a};
  \draw[line width=1.2pt,color=orange] (3.5,4.5) -- (3.5,0) node[below] {b};
\end{tikzpicture}
\end{center}

$$\int_a^b f(x)dx = \sum \limits_{k=0}^{n-1} \dfrac{b-a}{n} f(x_k) + F_1$$

\begin{Theorem}[Quadraturformeln]
  Seien $a < b$ reell, $f:[a,b] \to \R$ stetig, $n \in \N_{>0}$. Setze $x_k = a + \dfrac{b-a}{n}k$, $h = \dfrac{b-a}{n}$
  \begin{enumerate}
    \item Rechteckregel: Ist $f$ stetig differenzierbar, so gilt:
      $$\int_a^b f(x)dx = h (f(x_0) + f(x_1) + ... + f(x_{n-1})) + F_1$$
      mit $|F_1| \leq \dfrac{(b-a)^2}{2n} \cdot ||f''||_\infty$.
    \item Trapezregel: Ist $f$ von Klasse $C^2$, so gilt:
      $$\int_a^b f(x)dx = \dfrac{h}{2} (f(x_0) + 2 f(x_1) + 2 f(x_2) + ... + 2 f(x_{n-1}) + f(x_n)) + F_2$$
      mit $|F_2| \leq \dfrac{(b-a)^3}{6n^2} \cdot ||f''||_\infty$ (schon deutlich geringer).
    \item Simpson-Regel: Ist $f$ von Klasse $C^4$ und $n$ gerade, so gilt:
      $$\int_a^b f(x)dx = \dfrac{h}{3} (f(x_0) + 4 f(x_1) + 2 f(x_2) + 4 f(x_3) + 2f(x_4) + ... + 4 f(x_{n-1}) + f(x_n)) + F_3$$
      mit $|F_3| \leq \dfrac{(b-a)^5}{45 n^4} ||f^{(4)}||_\infty$.
  \end{enumerate}
\end{Theorem}

\begin{Bemerkung}
  Diese Verfahren funktionnieren für alle glatten Funktionen, also insbesondere auch für \textbf{nicht-analytische} Funktionen (,die keine Taylor-Entwicklung haben).
\end{Bemerkung}

\begin{Beweis}
  Siehe Skript.
  Insb 1, 2 als gute Wiederholung.

  Dies wird ausführlich in der Vorlesung über numerische Methoden behandelt.
\end{Beweis}

\begin{Beispiel}
  Berechne
  $$\int_0^1 \sin(t^2)dt$$
  bis auf 2 Nachkommastellen (im Dezimalsystem, duh).

  Benutzen wir die Trapezregel: $b-a = 1$, $n \geq 1$
  \begin{itemize}
    \item $f(t) = \sin(t^2)$
    \item $f'(t) = 2t \cos (t^2)$
    \item $f''(t) = 2 \cos(t^2) - 4t^2 \sin(t^2)$
  \end{itemize}
  Ohne große Berechnung können wir zumindest abschätzen, dass $||f''||_\infty \leq 6$ ist, und das reicht schon locker aus.
    $$\int_0^1 \sin(t^2)dt = \dfrac{1}{2n} \left( \sin(0) + 2\sin\left(\dfrac{1}{n^2}\right) + 2\sin\left(\dfrac{4}{n^2}\right) + \sin(1) \right) + F_2$$
    $$|F_2| \leq \dfrac{1^3}{6n^2} \cdot 6 = \dfrac{1}{n^2}$$
    Für eine Präzision bis auf 1 Hunderstel wählen wir: $n = 10$
\end{Beispiel}

\end{document}
